\chapter{Loss设计}
\label{cha:china}

Loss设计对于非监督学习的方法是及其重要的，本文提出的模型中，Loss的设计也同样十分关键，
并且花掉了笔者大部分的时间，本章即具体的介绍了模型各个部分Loss的设计以及设计思想。

\section{视差网络Loss设计}

在第一阶段的实验中，视差生成网络主要使用左右目的图像约束进行视差生成训练，本文会重点描述
这部分的设计。

视差网络的loss主要分为3个部分，分别介绍如下：

\textbf{区域相似性Loss}： 对于左右目图像来说，减去视差之后得到的对应点应该是相同的点，即
左目图像减去视差之后应当和右目图像对应，由于我们的视差是对每个像素点算的，算左右图像相似度
的时候当然应该对所有的像素点寻找对应点并且计算相似度。这种相似度是一种局部的性质，我们使用
经典的SSIM算法\cite{wang2004image}来表示这种局部的相似性质，并且对全局进行平均，公式表达如下：

$$ C_{ap}^{l} = \frac{1}{N}\sum_{i,j} \alpha \frac{1-SSIM(I_{ij}^l, \widetilde{I}_{ij}^l)}{2} + 
                (1 - \alpha)||I_{ij}^l - \widetilde{I}_{ij}^l|| $$
                
% TODO: add SSIM equation

\textbf{视差平滑性}： 我们有一个基本的假设，即视差应当是平滑变化的。这种假设是直观的，因为
在基线不变的情况下，视差基本上正比的反映了物体的深度，而物体的深度即是物体的轮廓，对于事业
中的大部分位点（除了前后不同的物体之外），轮廓的深度变化当然应该是平滑的。

$$ C_{ds}^{l} = \frac{1}{N}\sum_{i,j}|\partial_xd_{ij}^l|e^{-||\partial_xI_{ij}^l||} +
                |\partial_y d_{ij}^l|e^{-||\partial_y I_{ij}^l||}  $$
                
\textbf{左右视差一致性}： 这个想法是相当自然的，对于左右目图像中找到的对应点（注意，是加了视差
移动之后的对应点），他们的视差应当是等大反向的。数学描述如下：

$$ C_{lr}^l = \frac{1}{N} \sum_{i,j}|d_{ij}^l - d_{ij + d_{ij}^l}^r| $$

综合上述的三种Loss函数，结合左右目图像的结果，在训练过程中，总的loss值可以表示为下式所述：

$$ C_s = \alpha_{ap}(C_{ap}^l + C_{ap}^r) +
         \alpha_{ds}(C_{ds}^l + C_{ds}^r) +
         \alpha_{lr}(C_{lr}^l + C_{lr}^r)   $$

\section{位姿生成网络Loss设计}

对于位姿生成网络的loss函数，主要由两个部分组成：

\textbf{区域相似性Loss} 这个loss的名字和视差网络中的第一个相似，实际上他们的物理意义也
基本相似。对于位姿估计网络来说，我们可以根据前后的两帧连续的单目图像估计出一个6维的变换向量，
对第一帧应用了变换之后，理应能够在第二帧中找到一个和它对应的点，并且这两个点应当有区域的一致
性。假设相机内参矩阵为 $K$，深度信息为$D_{dep}$，
2帧间的变换矩阵为 $T_{k,k+1}$，对 $I_k$ 中的任意一个像素点 $p_k$ 应当有：

$$ p_{k+1} = K T_{k,k+1} D_{dep} K^{-1} p_k $$ 

那么对于整个图像 $I_k$ ， $I_{k+1}$ 我们可以根据变换矩阵 $T_{k, k+1}$ 分别合成 $I'_{k+1}$，
$I'_{k}$，并且分别有Loss：

$$ C_{ap}^k = \frac{1}{N} \sum_{i,j} \alpha \frac{1 - SSIM(I_{k, ij}, I'_{k, ij})}{2} +
              (1 - \alpha)||I_{k, ij} - I'_{k, ij}|| $$

$$ C_{ap}^{k+1} = \frac{1}{N} \sum_{i,j} \alpha \frac{1 - SSIM(I_{k+1, ij}, I'_{k+1, ij})}{2} +
              (1 - \alpha)||I_{k+1, ij} - I'_{k+1, ij}|| $$
              
\textbf{点云重合性loss} 根据前述的视差网络，我们可以拿到图像中每一个点的深度，进而生成3维点云，
重合性loss的想法相当自然，对于相邻的两帧点云 $P_k$ $P_{k+1}$，对他们应用变换矩阵T之后，这些
点云应当是重合的，假设我们分别对前述点云应用了变换矩阵 $T_{k, k+1}$及其逆，得到新的点云$P'_{k+1}$
$P'_{k}$，那么有loss函数

$$ C_{pt}^k = \frac{1}{N} \sum_{i,j}|p_{k, ij} - p'_{k, ij}| $$

$$ C_{pt}^{k+1} = \frac{1}{N} \sum_{i,j}|p_{k+1, ij} - p'_{k+1, ij}| $$

在实际实验中，还没有完成这部分的代码实现。但是，笔者认为位姿生成网络的这两个loss函数在物理意义上
有一定的相似性，因为2种loss本质上都是前后帧应用了变换矩阵之后对真实图像做差，因此也许可以在设计
上进行一定程度的简化。但是由于实验不够充分，没有足够的事实支撑，因而这一部分的讨论暂时按下不表，
留待之后的报告中讨论。
























